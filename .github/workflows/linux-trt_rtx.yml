name: linux-trt_rtx

on:
  workflow_dispatch:

jobs:
  build:
    runs-on: ubuntu-latest
    # 保持使用 Ubuntu 20.04 容器，为了 glibc 兼容性
    container:
      image: ubuntu:20.04

    strategy:
      fail-fast: false
      matrix:
        cuda_ver: ["12.9", "13.1"]
        python_ver: ["3.11"]

    env:
      DEBIAN_FRONTEND: noninteractive

    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      # 1. 基础环境安装
      - name: Install Base Dependencies
        run: |
          apt-get update
          apt-get install -y wget curl git build-essential ca-certificates tar unzip zip jq sudo libarchive-tools ninja-build lsb-release gnupg software-properties-common pkg-config zlib1g-dev libssl-dev libffi-dev openssl
          # libarchive-tools 包含 bsdtar 等工具，有时解压需要

      # 2. 获取 ORT 最新 Release Tag (修正点 1)
      - name: Get Latest ORT Tag
        id: get_tag
        run: |
          # 调用 GitHub API 获取最新 Release 的 tag_name
          LATEST_TAG=$(curl -sL https://api.github.com/repos/microsoft/onnxruntime/releases/latest | jq -r ".tag_name")
          echo "Latest tag detected: $LATEST_TAG"
          echo "tag=$LATEST_TAG" >> $GITHUB_OUTPUT

      # 3. Checkout ORT 代码 (使用最新 Tag)
      - name: Checkout ONNX Runtime
        uses: actions/checkout@v4
        with:
          repository: microsoft/onnxruntime
          path: onnxruntime
          ref: ${{ steps.get_tag.outputs.tag }} # 使用刚才获取的 Tag
          submodules: recursive

      # 4. 初始化 CUDA (使用 Jimver Action 自动缓存)
      - name: Setup CUDA
        uses: Jimver/cuda-toolkit@v0.2.30
        id: cuda-toolkit
        with:
          cuda: ${{ matrix.cuda_ver }}.0
          method: ${{ contains(matrix.cuda_ver, '13') && 'local' || 'network' }}
          # 安装 nvcc 和编译必要的库
        #   sub-packages: '["nvcc", "cudart", "visual_studio_integration"]'

      # 5. 初始化 TensorRT-RTX (使用我们定义的本地 Action)
      # 请确保 .github/actions/setup-trt-rtx/action.yml 文件存在 (见上一条回复)
      - name: Setup TensorRT-RTX
        uses: ./.github/actions/setup-trt-rtx
        with:
          cuda-version: ${{ matrix.cuda_ver }}
          # 如果你要针对 12.9 使用特定版本 TRT，可以在这里控制 inputs

      # 6. 安装 Python (用于编译 Wheel)
      - name: Setup Python 
        uses: actions/setup-python@v5
        with:
            python-version: ${{ matrix.python_ver }}
            # cache: 'pip'

      # 7. 安装 CMake (Ubuntu 20.04 自带太老)
      - name: Install CMake
        uses: jwlawson/actions-setup-cmake@v2.0
        with:
          cmake-version: '3.29.0'

      # 8. 执行构建
      - name: Build ORT
        working-directory: ${{ github.workspace }}
        run: |
          chmod +x build-onnxruntime-linux-trt_rtx.sh
          ./build-onnxruntime-linux-trt_rtx.sh
        env:
          ORT_PATH: onnxruntime
          # TRT_RTX_HOME 由 setup-trt-rtx Action 注入
          CUDA_VERSION: ${{ matrix.cuda_ver }}
          PYTHON_EXEC: python${{ matrix.python_ver }}

      - name: Upload Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: onnxruntime-linux-cuda${{ matrix.cuda_ver }}-rtx
          path: |
            ${{ github.workspace }}/output/*.7z
            ${{ github.workspace }}/output/*.whl